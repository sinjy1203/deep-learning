{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object-localization_reference.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSe0jh6cAPAHrn1gZzxsfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinjy1203/deep-learning/blob/master/object_localization_reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R6iTtEYnvee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import math\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.backend import epsilon\n",
        "\n",
        "# 0.35, 0.5, 0.75, 1.0\n",
        "ALPHA = 1.0\n",
        "\n",
        "# 96, 128, 160, 192, 224\n",
        "IMAGE_SIZE = 96\n",
        "\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 50\n",
        "\n",
        "MULTI_PROCESSING = False\n",
        "THREADS = 1\n",
        "\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "VALIDATION_CSV = \"validation.csv\"\n",
        "\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.paths = []\n",
        "\n",
        "        with open(csv_file, \"r\") as file:\n",
        "            # print(type(sum(1 for line in file)))\n",
        "            self.coords = np.zeros((int(sum(1 for line in file) / 2.0), 4))\n",
        "            # print(self.coords.shape)\n",
        "            file.seek(0)\n",
        "\n",
        "            reader = csv.reader(file, delimiter=\",\")\n",
        "            for index, row in enumerate(reader):\n",
        "                if index % 2 == 0:\n",
        "                    index = index // 2\n",
        "                    for i, r in enumerate(row[1:7]):\n",
        "                        row[i+1] = int(r)\n",
        "\n",
        "                    path, image_height, image_width, x0, y0, x1, y1, _, _ = row\n",
        "                    self.coords[index, 0] = x0 * IMAGE_SIZE / image_width\n",
        "                    self.coords[index, 1] = y0 * IMAGE_SIZE / image_height\n",
        "                    self.coords[index, 2] = (x1 - x0) * IMAGE_SIZE / image_width\n",
        "                    self.coords[index, 3] = (y1 - y0) * IMAGE_SIZE / image_height\n",
        "\n",
        "                    self.paths.append(path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.coords) / BATCH_SIZE)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_paths = self.paths[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
        "        batch_coords = self.coords[idx * BATCH_SIZE:(idx + 1) * BATCH_SIZE]\n",
        "\n",
        "        batch_images = np.zeros((len(batch_paths), IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n",
        "        for i, f in enumerate(batch_paths):\n",
        "            img = Image.open(f)\n",
        "            img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "            batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))\n",
        "            img.close()\n",
        "        print(batch_images.shape, batch_coords.shape)\n",
        "        return batch_images, batch_coords\n",
        "\n",
        "class Validation(Callback):\n",
        "    def __init__(self, generator):\n",
        "        self.generator = generator\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        mse = 0\n",
        "        intersections = 0\n",
        "        unions = 0\n",
        "\n",
        "        for i in range(len(self.generator)):\n",
        "            batch_images, gt = self.generator[i]\n",
        "            pred = self.model.predict_on_batch(batch_images)\n",
        "            mse += np.linalg.norm(gt - pred, ord='fro') / pred.shape[0]\n",
        "\n",
        "            pred = np.maximum(pred, 0)\n",
        "\n",
        "            diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n",
        "            diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n",
        "            intersection = np.maximum(diff_width, 0) * np.maximum(diff_height, 0)\n",
        "\n",
        "            area_gt = gt[:,2] * gt[:,3]\n",
        "            area_pred = pred[:,2] * pred[:,3]\n",
        "            union = np.maximum(area_gt + area_pred - intersection, 0)\n",
        "\n",
        "            intersections += np.sum(intersection * (union > 0))\n",
        "            unions += np.sum(union)\n",
        "\n",
        "        iou = np.round(intersections / (unions + epsilon()), 4)\n",
        "        logs[\"val_iou\"] = iou\n",
        "\n",
        "        mse = np.round(mse, 4)\n",
        "        logs[\"val_mse\"] = mse\n",
        "\n",
        "        print(\" - val_iou: {} - val_mse: {}\".format(iou, mse))\n",
        "\n",
        "def create_model(trainable=False):\n",
        "    model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA)\n",
        "\n",
        "    # to freeze layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    x = model.layers[-1].output\n",
        "    x = Conv2D(4, kernel_size=3, name=\"coords\")(x)\n",
        "    x = Reshape((4,))(x)\n",
        "\n",
        "    return Model(inputs=model.input, outputs=x)\n",
        "\n",
        "def main():\n",
        "    model = create_model()\n",
        "    model.summary()\n",
        "\n",
        "    train_datagen = DataGenerator(TRAIN_CSV)\n",
        "    validation_datagen = Validation(generator=DataGenerator(VALIDATION_CSV))\n",
        "\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\"model-{val_iou:.2f}.h5\", monitor=\"val_iou\", verbose=1, save_best_only=True,\n",
        "                                 save_weights_only=True, mode=\"max\")\n",
        "    stop = EarlyStopping(monitor=\"val_iou\", patience=PATIENCE, mode=\"max\")\n",
        "    reduce_lr = ReduceLROnPlateau(monitor=\"val_iou\", factor=0.2, patience=10, min_lr=1e-7, verbose=1, mode=\"max\")\n",
        "\n",
        "    model.fit_generator(generator=train_datagen,\n",
        "                        epochs=EPOCHS,\n",
        "                        callbacks=[validation_datagen, checkpoint, reduce_lr, stop],\n",
        "                        workers=THREADS,\n",
        "                        use_multiprocessing=MULTI_PROCESSING,\n",
        "                        shuffle=True,\n",
        "                        verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrcPWPzan4tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from localization import create_model, IMAGE_SIZE\n",
        "from keras.applications.mobilenetv2 import preprocess_input\n",
        "\n",
        "WEIGHTS_FILE = \"model-0.47.h5\"\n",
        "IMAGES = \"images/*jpg\"\n",
        "\n",
        "def main():\n",
        "    model = create_model()\n",
        "    model.load_weights(WEIGHTS_FILE)\n",
        "\n",
        "    for filename in glob.glob(IMAGES):\n",
        "        unscaled = cv2.imread(filename)\n",
        "        image_height, image_width, _ = unscaled.shape\n",
        "\n",
        "        image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
        "\n",
        "        region = model.predict(x=np.array([feat_scaled]))[0]\n",
        "\n",
        "        x0 = int(region[0] * image_width / IMAGE_SIZE)\n",
        "        y0 = int(region[1] * image_height / IMAGE_SIZE)\n",
        "\n",
        "        x1 = int((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
        "        y1 = int((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
        "\n",
        "        cv2.rectangle(unscaled, (x0, y0), (x1, y1), (0, 0, 255), 1)\n",
        "        cv2.imshow(\"image\", unscaled)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYE8st-aoWRx",
        "colab_type": "text"
      },
      "source": [
        "참고 문헌 https://github.com/lars76/object-localization"
      ]
    }
  ]
}