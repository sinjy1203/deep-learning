{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_cnn_resnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1Vr3xwy0US52K/9RrBA45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinjy1203/deep-learning/blob/master/cifar10_cnn_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXzQWijBOxrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "8c0fb1f6-bd01-4c6c-9b5a-0b19b07f618d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slPfrbaSt8XY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a98fc223-ad45-4a11-bf9a-4c5d48efe053"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from functools import partial\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train.shape, x_test.shape\n",
        "x_train = x_train.astype(np.float32) / 255.0\n",
        "x_test = x_test.astype(np.float32) / 255.0\n",
        "y_train = y_train.astype(np.int32).reshape(-1)\n",
        "y_test = y_test.astype(np.int32).reshape(-1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val = train_test_split(x_train, test_size=0.2, random_state=42)\n",
        "y_train, y_val = train_test_split(y_train, test_size=0.2, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuE5WlyauEbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "7fb3c413-953b-40ce-f61d-c23e21083f40"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def shuffle_batch(x, y, batch_size):\n",
        "  rnd_idx = np.random.permutation(len(x))\n",
        "  n_batch = len(x) // batch_size\n",
        "  for batch_idx in np.array_split(rnd_idx, n_batch):\n",
        "    xs, ys = x[batch_idx], y[batch_idx]\n",
        "    yield xs, ys\n",
        "\n",
        "name = ['drop', 'layer', 'bn', 'act']\n",
        "name_list = []\n",
        "for i in range(4):\n",
        "  bb = [b + str(i) for b in name]\n",
        "  name_list.append(bb)\n",
        "  bb = []\n",
        "\n",
        "n_layers=4\n",
        "n_epochs = 101\n",
        "batch_size = 1000\n",
        "x = tf.placeholder(dtype=tf.float32, shape=[None, 32, 32, 3], name=\"x\")\n",
        "y = tf.placeholder(dtype=tf.int32, shape=[None], name=\"y\")\n",
        "training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
        "he_init = tf.variance_scaling_initializer()\n",
        "\n",
        "##########partial########\n",
        "conv = partial(tf.layers.conv2d, kernel_size=3, padding='SAME', kernel_initializer=he_init)\n",
        "conv_re = partial(tf.layers.conv2d, kernel_size=1, strides=2, padding='SAME', kernel_initializer=he_init)\n",
        "max_pool = partial(tf.layers.max_pooling2d, pool_size=2, padding='SAME', strides=2)\n",
        "bn = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
        "drop = partial(tf.layers.dropout, rate=0.5, training=training)\n",
        "\n",
        "##########convolution########\n",
        "conv1 = conv(x, filters=64, strides=1, name='conv1')\n",
        "bn1 = bn(conv1, name='bn1')\n",
        "act1 = tf.nn.relu(bn1)\n",
        "max_pool1 = max_pool(act1, pool_size=3, name='max_pool1')\n",
        "\n",
        "conv2 = conv(max_pool1, filters=64, strides=1, name='conv2')\n",
        "bn2 = bn(conv2, name='bn2')\n",
        "act2 = tf.nn.relu(bn2, name='act2')\n",
        "conv2_2 = conv(act2, filters=64, strides=1, name='conv2_2')\n",
        "bn2_2 = bn(conv2_2, name='bn2_2')\n",
        "res2 = tf.add(max_pool1, bn2_2, name='res2')\n",
        "act2_2 = tf.nn.relu(res2, name='act2_2')\n",
        "\n",
        "conv3 = conv(act2_2, filters=64, strides=1, name='conv3')\n",
        "bn3 = bn(conv3, name='bn3')\n",
        "act3 = tf.nn.relu(bn3, name='act3')\n",
        "conv3_2 = conv(act3, filters=64, strides=1, name='conv3_2')\n",
        "bn3_2 = bn(conv3_2, name='bn3_2')\n",
        "res3 = tf.add(act2_2, bn3_2, name='res3')\n",
        "act3_2 = tf.nn.relu(res3, name='act3_2')\n",
        "#####\n",
        "\n",
        "conv4 = conv(act3_2, filters=128, strides=2, name='conv4')\n",
        "bn4 = bn(conv4, name='bn4')\n",
        "act4 = tf.nn.relu(bn4, name='act4')\n",
        "conv4_2 = conv(act4, filters=128, strides=1, name='conv4_2')\n",
        "bn4_2 = bn(conv4_2, name='bn4_2')\n",
        "conv4_re = conv_re(act3_2, filters=128, name='conv4_re')\n",
        "bn4_re = bn(conv4_re, name='bn4_re')\n",
        "res4 = tf.add(bn4_re, bn4_2, name='res4')\n",
        "act4_2 = tf.nn.relu(res4, name='act4_2')\n",
        "\n",
        "conv5 = conv(act4_2, filters=128, strides=1, name='conv5')\n",
        "bn5 = bn(conv5, name='bn5')\n",
        "act5 = tf.nn.relu(bn5, name='act5')\n",
        "conv5_2 = conv(act5, filters=128, strides=1, name='conv5_2')\n",
        "bn5_2 = bn(conv5_2, name='bn5_2')\n",
        "res5 = tf.add(act4_2, bn5_2, name='res5')\n",
        "act5_2 = tf.nn.relu(res5, name='act5_2')\n",
        "###\n",
        "\n",
        "conv6 = conv(act5_2, filters=256, strides=2, name='conv6')\n",
        "bn6 = bn(conv6, name='bn6')\n",
        "act6 = tf.nn.relu(bn6, name='act6')\n",
        "conv6_2 = conv(act6, filters=256, strides=1, name='conv6_2')\n",
        "bn6_2 = bn(conv6_2, name='bn6_2')\n",
        "conv6_re = conv_re(act5_2, filters=256, name='conv6_re')\n",
        "bn6_re = bn(conv6_re, name='bn6_re')\n",
        "res6 = tf.add(bn6_re, bn6_2, name='res6')\n",
        "act6_2 = tf.nn.relu(res6, name='act6_2')\n",
        "\n",
        "conv7 = conv(act6_2, filters=256, strides=1, name='conv7')\n",
        "bn7 = bn(conv7, name='bn7')\n",
        "act7 = tf.nn.relu(bn7, name='act7')\n",
        "conv7_2 = conv(act7, filters=256, strides=1, name='conv7_2')\n",
        "bn7_2 = bn(conv7_2, name='bn7_2')\n",
        "res7 = tf.add(act6_2, bn7_2, name='res7')\n",
        "act7_2 = tf.nn.relu(res7, name='act7_2')\n",
        "\n",
        "###############\n",
        "\n",
        "avg_pool = tf.layers.average_pooling2d(act7_2, pool_size=4, strides=(1,1), padding='VALID', name='avg_pool')\n",
        "reshape = tf.reshape(avg_pool, shape=[-1, 256])\n",
        "\n",
        "####fully connected#####\n",
        "drop5 = tf.layers.dropout(reshape, rate=0.5, training=training, name=\"drop5\")\n",
        "layer5 = tf.layers.dense(drop5, 10, kernel_initializer=he_init, name=\"layer5\")\n",
        "################################\n",
        "\n",
        "logits = layer5\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits, name=\"xentropy\")\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "optimizer = tf.train.AdamOptimizer(0.001, name=\"optimizer\")\n",
        "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
        "\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "cost_sum = []\n",
        "file_writer = tf.summary.FileWriter(\"./\", tf.get_default_graph())\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  for epoch in range(n_epochs):\n",
        "    for xs, ys in shuffle_batch(x_train, y_train, batch_size):\n",
        "      _, cost, __ = sess.run([training_op, loss, extra_update_ops], feed_dict={x: xs, y: ys, training: True})\n",
        "      cost_sum.append(cost)\n",
        "    cost_avg = sum(cost_sum) / len(cost_sum)\n",
        "    if epoch % 10 == 0:\n",
        "      acc_val = sess.run(accuracy, feed_dict={x: x_val, y: y_val})\n",
        "      print(\"{}번째\\t손실: {}\\t테스트정확도: {}\".format(epoch, cost_avg, acc_val))\n",
        "    cost_avg = 0.0\n",
        "  save_path = saver.save(sess, \"./model\")\n",
        "  print(\"걸린시간: \", time.time()-start)\n",
        "# with tf.Session() as sess:\n",
        "#   init.run()\n",
        "#   a = conv3.eval(feed_dict={x: x_test, y: y_test})\n",
        "#   print(a.shape)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0번째\t손실: 1.6507060199975967\t테스트정확도: 0.46869999170303345\n",
            "10번째\t손실: 0.543008285752413\t테스트정확도: 0.6966999769210815\n",
            "20번째\t손실: 0.308052986649619\t테스트정확도: 0.7508000135421753\n",
            "30번째\t손실: 0.21887789017055184\t테스트정확도: 0.718500018119812\n",
            "40번째\t손실: 0.17083275024040898\t테스트정확도: 0.7508999705314636\n",
            "50번째\t손실: 0.14143136807548468\t테스트정확도: 0.7468000054359436\n",
            "60번째\t손실: 0.12127771100246912\t테스트정확도: 0.7401000261306763\n",
            "70번째\t손실: 0.10560314365183855\t테스트정확도: 0.7597000002861023\n",
            "80번째\t손실: 0.0944203402931601\t테스트정확도: 0.7979999780654907\n",
            "90번째\t손실: 0.08405592905668487\t테스트정확도: 0.8029999732971191\n",
            "100번째\t손실: 0.07573852177955058\t테스트정확도: 0.8027999997138977\n",
            "걸린시간:  1926.379147052765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IAPjlUpuFlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e420ab45-cb70-4e5d-f7f8-0f36f70a4052"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, \"./model\")\n",
        "  acc_test = accuracy.eval(feed_dict={x: x_test, y: y_test})\n",
        "  print(acc_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model\n",
            "0.793\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}