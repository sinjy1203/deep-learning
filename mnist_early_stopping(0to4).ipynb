{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_early_stopping(0to4).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWq4B2Qkjmqtu0b3nBn0Vj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinjy1203/deep-learning/blob/master/mnist_early_stopping(0to4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tDlg6xVa-O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "ccf02d33-233a-4223-bb2e-7094bb15c523"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtltMtrybj5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeXD25TFcDcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test = x_train.astype(np.float32).reshape(-1, 28*28), x_test.astype(np.float32).reshape(-1, 28*28)\n",
        "y_train, y_test = y_train.astype(np.int32), y_test.astype(np.int32)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val = train_test_split(x_train, test_size=0.2, random_state=42)\n",
        "y_train, y_val = train_test_split(y_train, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ylMgmuS1h2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "162ec665-1d12-4652-e72e-ef344408bd3c"
      },
      "source": [
        "a = np.array([[1,2,3],\n",
        "              [4,5,6],\n",
        "              [7,8,9]])\n",
        "np.delete(a, (0, 1), axis=0)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDim6Ht2SKBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "not_idx = []\n",
        "not2_idx = []\n",
        "for idx, i in enumerate(y_train):\n",
        "  if (i >= 5) and (i <= 9):\n",
        "    not_idx.append(idx)\n",
        "for idx, i in enumerate(y_val):\n",
        "  if (i >= 5) and (i <= 9):\n",
        "    not2_idx.append(idx)\n",
        "y_train = np.delete(y_train, (not_idx), axis=0)\n",
        "x_train = np.delete(x_train, (not_idx), axis=0)\n",
        "y_val = np.delete(y_val, (not2_idx), axis=0)\n",
        "x_val = np.delete(x_val, (not2_idx), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cedIauq1dR2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "abc8ad2b-d389-4b2d-8dd8-0732b1381d13"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "import time\n",
        "from functools import partial\n",
        "\n",
        "def batch_shuffle(x, y, batch_size):\n",
        "  rnd_idx = np.random.permutation(len(x))\n",
        "  n_batch = len(x) // batch_size\n",
        "  for batch_idx in np.array_split(rnd_idx, n_batch):\n",
        "    batch_x = x[batch_idx]\n",
        "    batch_y = y[batch_idx]\n",
        "    yield batch_x, batch_y\n",
        "\n",
        "x = tf.placeholder(dtype=tf.float32, shape=(None, 28*28), name='x')\n",
        "y = tf.placeholder(dtype=tf.int64, shape=(None), name='y')\n",
        "he_init = tf.variance_scaling_initializer()\n",
        "layer = partial(tf.layers.dense, units=100, activation=tf.nn.elu, kernel_initializer=he_init)\n",
        "\n",
        "layer1 = layer(x)\n",
        "layer2 = layer(layer1)\n",
        "layer3 = layer(layer2)\n",
        "layer4 = layer(layer3)\n",
        "layer5 = layer(layer4)\n",
        "logits = tf.layers.dense(layer5, 5, kernel_initializer=he_init)\n",
        "\n",
        "pred = tf.nn.softmax(logits)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(0.001)\n",
        "training_op = optimizer.minimize(loss)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred, axis=1), y), dtype=tf.float32))\n",
        "\n",
        "n_epochs = 101\n",
        "batch_size = 100\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# with tf.Session() as sess:\n",
        "#   sess.run(init)\n",
        "#   for epoch in range(n_epochs):\n",
        "#     for xs, ys in batch_shuffle(x_train, y_train, batch_size):\n",
        "#       sess.run(training_op, feed_dict={x: xs, y: ys})\n",
        "#     if epoch % 10 == 0:\n",
        "#       acc = accuracy.eval(feed_dict={x: x_val, y: y_val})\n",
        "#       print(epoch, \"   \", acc)\n",
        "#   # acc1 = accuracy.eval(feed_dict={x: x_test, y: y_test})\n",
        "#   # print(\"최종 정확도: \", acc1)\n",
        "\n",
        "#######조기종료#########\n",
        "epoch = 0\n",
        "best_loss = np.infty\n",
        "max_count = 10\n",
        "mis_count = 0\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  while(True):\n",
        "    epoch += 1\n",
        "    for xs, ys in batch_shuffle(x_train, y_train, batch_size):\n",
        "      sess.run(training_op, feed_dict={x: xs, y: ys})   # 트레이닝\n",
        "    cost, acc = sess.run([loss, accuracy], feed_dict={x: x_val, y: y_val})   #val의 손실과 정확도\n",
        "    # if epoch % 10 == 0:\n",
        "    #   print(\"{}번째 손실: {:.6f}  정확도: {:.6f}\".format(epoch, cost, acc))    #일정 간격 현상황 프린트\n",
        "    if cost < best_loss:\n",
        "      save_path = saver.save(sess, \"/content/gdrive/My Drive/tmp/my_model_0to4.ckpt\")\n",
        "      best_loss = cost\n",
        "      best_accuracy = acc   \n",
        "      mis_count = 0                         # 손실이 줄어들때\n",
        "    else:                                          # 손실이 줄어들지 않을때\n",
        "      mis_count += 1\n",
        "      if mis_count == 1:\n",
        "        print(\"위기상황!!!!!!\")\n",
        "      if mis_count <= max_count:                  # 손실이 줄어들지 않은경우가 5번 이하일때\n",
        "        print(\"{}번째 손실: {:.6f}  정확도: {:.6f}  최선의 손실: {:.6f}  최선의 정확도: {:.6f}\".format(mis_count, cost, acc, best_loss, best_accuracy))\n",
        "      else:                                   # 손실이 줄어들지 않은경우가 5번 넘어가면 아웃\n",
        "        break\n",
        "\n",
        "    \n",
        "  # acc1 = accuracy.eval(feed_dict={x: x_test, y: y_test})\n",
        "  # print(\"최종 정확도: \", acc1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "위기상황!!!!!!\n",
            "1번째 손실: 0.081094  정확도: 0.978404  최선의 손실: 0.070283  최선의 정확도: 0.979888\n",
            "위기상황!!!!!!\n",
            "1번째 손실: 0.095904  정확도: 0.979888  최선의 손실: 0.057069  최선의 정확도: 0.985493\n",
            "2번째 손실: 0.070595  정확도: 0.983185  최선의 손실: 0.057069  최선의 정확도: 0.985493\n",
            "위기상황!!!!!!\n",
            "1번째 손실: 0.059685  정확도: 0.987306  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "2번째 손실: 0.080431  정확도: 0.984998  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "3번째 손실: 0.080695  정확도: 0.985328  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "4번째 손실: 0.050412  정확도: 0.988955  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "5번째 손실: 0.057278  정확도: 0.989285  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "6번째 손실: 0.075875  정확도: 0.981042  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "7번째 손실: 0.059379  정확도: 0.987141  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "8번째 손실: 0.058692  정확도: 0.987801  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "9번째 손실: 0.071260  정확도: 0.985493  최선의 손실: 0.046795  최선의 정확도: 0.987801\n",
            "10번째 손실: 0.065676  정확도: 0.987306  최선의 손실: 0.046795  최선의 정확도: 0.987801\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}